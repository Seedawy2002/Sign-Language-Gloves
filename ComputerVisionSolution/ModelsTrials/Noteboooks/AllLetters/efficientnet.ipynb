{"cells":[{"cell_type":"markdown","metadata":{"id":"CaGlG4jVhum6"},"source":["# **Notebook overview**"]},{"cell_type":"markdown","metadata":{"id":"yKS3Zp3mhum9"},"source":["\n","This notebook is structured to implement a real-time sign language detection systemo on ArSL dataset. It includes data preprocessing, model training, and evaluation steps designed to efficiently process and recognize sign language from input data.\n"]},{"cell_type":"markdown","metadata":{"id":"oRL5c-I5hum-"},"source":["The following are the preprocessing techniques applied to the chosen subset of the dataset.\n","\n","1. **Image resizing**: The images are resized to (3, 224, 224) where 3 represents the number of channels (RGB) in the image and (224, 224) represents the 2D dimensions of each image.\n","\n","2. **Grayscale conversion**: Converting images to grayscale can reduce the computational complexity as it reduces the number of channels in each image from three (RGB) to one.\n","\n","\n","3. **Background Subtraction** : To focus the model on the hand gestures, it's helpful to remove or standardize the background. Techniques like thresholding or using a consistent backdrop during image capture can be effective.\n","\n","4. **Normalization**: Scaling pixel values to a range, typically between 0 and 1, helps in speeding up convergence during training.\n","\n","5. **Data Augmentation**: To make the model robust to various orientations and scales, augmenting the dataset with transformed images (e.g., rotations, scaling, translations, flipping) is beneficial."]},{"cell_type":"markdown","metadata":{"id":"hJeAYwZdCW_E"},"source":["## Needed libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:37.916879Z","iopub.status.busy":"2024-05-20T05:39:37.916526Z","iopub.status.idle":"2024-05-20T05:39:37.922936Z","shell.execute_reply":"2024-05-20T05:39:37.921952Z","shell.execute_reply.started":"2024-05-20T05:39:37.916851Z"},"id":"D30ringWCWp4","trusted":true},"outputs":[],"source":["import numpy as np\n","import cv2\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import os\n","import torch\n","import pandas as pd\n","import torch.nn as nn\n","import torchvision.transforms.v2 as transforms\n","import torchvision.models\n","from  torch.utils.data import DataLoader, Dataset\n","from albumentations.pytorch import ToTensorV2"]},{"cell_type":"markdown","metadata":{"id":"cLth9iMchunB"},"source":["# **Data Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"YmKxPu6sBFKT"},"source":["## Creating The DataFrams For All Characters"]},{"cell_type":"markdown","metadata":{"id":"OdjBhCqxhunC"},"source":["The code begins by defining the destination_folder, which is the directory containing the dataset. It then proceeds to gather and organize all image files and their associated labels into a structured format, specifically a Pandas DataFrame. This DataFrame will serve as the foundation for further data handling tasks such as preprocessing, model training, and evaluation.This code block efficiently organizes a potentially large and unstructured dataset into a manageable and easy-to-access format, setting the stage for more advanced data processing and machine learning tasks."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:37.937638Z","iopub.status.busy":"2024-05-20T05:39:37.936957Z","iopub.status.idle":"2024-05-20T05:39:38.748452Z","shell.execute_reply":"2024-05-20T05:39:38.747472Z","shell.execute_reply.started":"2024-05-20T05:39:37.937612Z"},"trusted":true,"id":"I2KdIr24hunC","outputId":"42c8162b-cdac-4878-bc04-385ada793f1d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_path</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/kaggle/input/rgb-arabic-alphabets-sign-langua...</td>\n","      <td>Zain</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/kaggle/input/rgb-arabic-alphabets-sign-langua...</td>\n","      <td>Zain</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/kaggle/input/rgb-arabic-alphabets-sign-langua...</td>\n","      <td>Zain</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/kaggle/input/rgb-arabic-alphabets-sign-langua...</td>\n","      <td>Zain</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/kaggle/input/rgb-arabic-alphabets-sign-langua...</td>\n","      <td>Zain</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          image_path label\n","0  /kaggle/input/rgb-arabic-alphabets-sign-langua...  Zain\n","1  /kaggle/input/rgb-arabic-alphabets-sign-langua...  Zain\n","2  /kaggle/input/rgb-arabic-alphabets-sign-langua...  Zain\n","3  /kaggle/input/rgb-arabic-alphabets-sign-langua...  Zain\n","4  /kaggle/input/rgb-arabic-alphabets-sign-langua...  Zain"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["destination_folder = \"/kaggle/input/rgb-arabic-alphabets-sign-language-dataset/RGB ArSL dataset\"\n","\n","\n","# Get list of .npy files in the directory\n","char_folders = [file for file in os.listdir(destination_folder)]\n","\n","# Initialize lists to store image paths and labels\n","images_paths = []\n","labels = []\n","\n","# Iterate through each character folder\n","for char_folder in char_folders:\n","    # Extract label from the folder name\n","    label = char_folder\n","\n","    # Get the full path to the character folder\n","    full_path = os.path.join(destination_folder, char_folder)\n","\n","    # Get all file paths within the character folder\n","    files_in_folder = [os.path.join(full_path, file) for file in os.listdir(full_path)]\n","\n","    # Append the list of image paths to images_paths\n","    images_paths.extend(files_in_folder)\n","\n","    # Append the label to the labels list\n","    labels.extend([label] * len(files_in_folder))\n","\n","\n","data=pd.DataFrame({\"image_path\":images_paths,\"label\":labels})\n","data.head()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-_5lQvgchunE"},"source":["## Data Preparation and Encoding"]},{"cell_type":"markdown","metadata":{"id":"glxZ0OSEhunE"},"source":["This section of the notebook focuses on preparing the dataset for training. It includes splitting the data into training and testing sets, encoding the labels, and resetting the indices of the DataFrames to ensure clean and organized data. Each step is crucial for setting up a structured and efficient data pipeline, which is essential for the successful training and evaluation of machine learning models.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:38.750651Z","iopub.status.busy":"2024-05-20T05:39:38.750349Z","iopub.status.idle":"2024-05-20T05:39:38.772219Z","shell.execute_reply":"2024-05-20T05:39:38.771256Z","shell.execute_reply.started":"2024-05-20T05:39:38.750627Z"},"id":"ynAm_QT6TK-e","trusted":true},"outputs":[],"source":["train_data,test_data,train_labels,test_labels= train_test_split(data['image_path'],data['label'], test_size=0.2, stratify=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:38.774186Z","iopub.status.busy":"2024-05-20T05:39:38.773657Z","iopub.status.idle":"2024-05-20T05:39:38.780572Z","shell.execute_reply":"2024-05-20T05:39:38.779490Z","shell.execute_reply.started":"2024-05-20T05:39:38.774150Z"},"trusted":true,"id":"6ln7WQy-hunF","outputId":"7f86d3de-c32c-434d-db0b-c99ce0c1c144"},"outputs":[{"name":"stdout","output_type":"stream","text":["train data shape  (6284,) test data shape (1572,)\n"]}],"source":["print(\"train data shape \",train_data.shape,\"test data shape\" ,test_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rrDmFguqhunG"},"outputs":[],"source":["# One hot encoding\n","\n","label_encoder = LabelEncoder()\n","train_labels = label_encoder.fit_transform(train_labels)\n","test_labels = label_encoder.fit_transform(test_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEMjFwA3hunH"},"outputs":[],"source":["# Resetting indices\n","train_data = train_data.reset_index(drop=True)\n","test_data = test_data.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"6RNjsGvghunH"},"source":["## Data Preparation and Encoding"]},{"cell_type":"markdown","metadata":{"id":"Ao6eXwhNhunH"},"source":["### Custom Dataset Handling and Image Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"Dt8uEOvohunI"},"source":["This section focuses on creating a custom dataset class and applying a series of image transformations for preprocessing. The primary goal here is to ensure that the images are properly formatted and augmented to enhance the model's ability to generalize from the training data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:38.784085Z","iopub.status.busy":"2024-05-20T05:39:38.783174Z","iopub.status.idle":"2024-05-20T05:39:38.791597Z","shell.execute_reply":"2024-05-20T05:39:38.790515Z","shell.execute_reply.started":"2024-05-20T05:39:38.784038Z"},"id":"TPiBe5HHTviG","trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, image,labels, transforms=None):\n","        self.image = image\n","        self.labels=labels\n","        self.transforms = transforms\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        label = self.labels[idx]\n","        # Read the image using OpenCV\n","        image = cv2.imread(self.image[idx])\n","        # Convert the image from BGR to RGB (OpenCV uses BGR by default)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        # Convert the image to a PIL Image\n","        image = Image.fromarray(image)\n","\n","        if self.transforms:\n","            image = self.transforms(image)\n","\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:38.813463Z","iopub.status.busy":"2024-05-20T05:39:38.812728Z","iopub.status.idle":"2024-05-20T05:39:38.822792Z","shell.execute_reply":"2024-05-20T05:39:38.821763Z","shell.execute_reply.started":"2024-05-20T05:39:38.813437Z"},"id":"8Sk0_kxrat5T","outputId":"da9698f8-e0d5-4c01-fe27-17a2d3f80ab8","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n","  warnings.warn(\n"]}],"source":["# Can add multiple transformations to enhance the training of the model\n","\n","train_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","test_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:38.824456Z","iopub.status.busy":"2024-05-20T05:39:38.824112Z","iopub.status.idle":"2024-05-20T05:39:38.832666Z","shell.execute_reply":"2024-05-20T05:39:38.831637Z","shell.execute_reply.started":"2024-05-20T05:39:38.824422Z"},"id":"4XqGe9zVUK4h","trusted":true},"outputs":[],"source":["trainset = MyDataset(train_data,train_labels,train_transforms)\n","trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","testset = MyDataset(test_data,test_labels,test_transforms)\n","testloader = DataLoader(testset, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"o0bjXJEFhunK"},"source":["## **Comprehensive Model Setup, Training, and Evaluation**"]},{"cell_type":"markdown","metadata":{"id":"7zBaNwFhhunK"},"source":["This section outlines the setup, training, and evaluation of The EfficientNet model, designed for efficiency and scalability in image classification tasks, demonstrated strong learning capabilities in training results. Initially, the model is loaded with pre-trained weights and adjusted to match the specific requirements of the dataset by modifying its final layers. The training process is facilitated by defining an appropriate loss function (cross-entropy) and an optimizer (Adam), which are crucial for optimizing the model's performance. The section includes detailed training and validation functions that operate over multiple epochs to incrementally improve accuracy and reduce loss."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BoOwgD8zhunK","outputId":"f4535fc6-1138-465d-bc97-8b2045ebb9d4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n","100%|██████████| 20.5M/20.5M [00:00<00:00, 112MB/s] \n"]},{"name":"stdout","output_type":"stream","text":["EfficientNet(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (2): Conv2dNormActivation(\n","            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n","            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n","      )\n","    )\n","    (4): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n","      )\n","    )\n","    (8): Conv2dNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=True)\n","    (1): Linear(in_features=1280, out_features=31, bias=True)\n","  )\n",")\n"]}],"source":["import torchvision.models as models\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","\n","# Load the pre-trained EfficientNet-B0 model\n","model_efficientnet = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n","for param in model_efficientnet.parameters():\n","    param.requires_grad = False\n","\n","# Replace the last fully connected layer for our specific case\n","num_features = model_efficientnet.classifier[1].in_features\n","model_efficientnet.classifier[1] = nn.Linear(num_features, 31)\n","model_efficientnet = model_efficientnet.to(device)\n","\n","# Loss function and optimizer\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model_efficientnet.parameters(), lr=0.001)\n","\n","# Print model architecture (optional)\n","print(model_efficientnet)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:38.834193Z","iopub.status.busy":"2024-05-20T05:39:38.833891Z","iopub.status.idle":"2024-05-20T05:39:38.841807Z","shell.execute_reply":"2024-05-20T05:39:38.840837Z","shell.execute_reply.started":"2024-05-20T05:39:38.834170Z"},"id":"iI-s0bvE0zg0","trusted":true},"outputs":[],"source":["def train(model, dataloader, loss, optimizer,device='cuda'):\n","    model.train()\n","    acc = []\n","    lss_history = []\n","    for data,labels in dataloader:\n","        data=data.to(device)\n","        labels=labels.to(device)\n","        optimizer.zero_grad()\n","\n","        pred = model(data)\n","        lss = loss(pred, labels)\n","        lss.backward()\n","        optimizer.step()\n","        # acc calculations\n","        lss_history.append(lss.item())\n","        acc.append(((pred.argmax(axis = 1) == labels).type(torch.float)).mean().item())\n","    return np.mean(lss_history) ,np.mean(acc)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:38.845051Z","iopub.status.busy":"2024-05-20T05:39:38.844557Z","iopub.status.idle":"2024-05-20T05:39:38.852295Z","shell.execute_reply":"2024-05-20T05:39:38.851138Z","shell.execute_reply.started":"2024-05-20T05:39:38.845026Z"},"trusted":true,"id":"nDuIO9tThunL"},"outputs":[],"source":["# function to validate the model\n","def validate(model, dataloader, loss_func,device='cuda'):\n","    model.eval()\n","    loss_values = []\n","    acc_values = []\n","    with torch.no_grad():\n","        for data,labels in dataloader:\n","            data=data.to(device)\n","            labels=labels.to(device)\n","            pred = model(data)\n","            loss = loss_func(pred, labels)\n","            loss_values.append(loss.item())\n","            acc_value = (pred.argmax(axis = 1) == labels).type(torch.float32)\n","            acc_values.append(acc_value.mean().item())\n","    return np.mean(loss_values), np.mean(acc_values)"]},{"cell_type":"markdown","metadata":{"id":"Ucgj__UEhunL"},"source":["# **Results Overview from Initial Training Cycles**"]},{"cell_type":"markdown","metadata":{"id":"R2lLgl0bhunM"},"source":["The results from the initial training cycles using the EfficientNet model demonstrate promising progress in both training and testing phases. Over the first three epochs, the training loss decreased significantly from 2.722 to 1.530, while training accuracy improved from 33.6% to 63.6%. This rapid improvement indicates that EfficientNet is effectively learning and adapting to the dataset. Additionally, the testing accuracy also showed consistent growth, starting at 54.2% and reaching 65.1% by the third epoch. These outcomes highlight EfficientNet's strengths in handling complex image classification tasks efficiently, achieving substantial gains in performance over just a few epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:39.355170Z","iopub.status.busy":"2024-05-20T05:39:39.354863Z","iopub.status.idle":"2024-05-20T05:39:39.361133Z","shell.execute_reply":"2024-05-20T05:39:39.360184Z","shell.execute_reply.started":"2024-05-20T05:39:39.355146Z"},"id":"OfIt-oMo1Vg5","trusted":true},"outputs":[],"source":["def tune_model(epochs, model, train_dataloader, test_dataloader, loss_func, optimizer):\n","    for epoch in range(epochs):\n","        train_loss, train_acc = train(model, train_dataloader, loss_func, optimizer,device=device)\n","        test_loss, test_acc= validate(model, test_dataloader, loss,device=device)\n","        print(f\"Epoch : {epoch + 1} || Train loss : {train_loss:5.3f} || Train accuracy : {train_acc:5.3f}\", end=\"\")\n","        print(f\" Test loss : {test_loss:5.3f} || Test accuracy : {test_acc:5.3f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T05:39:39.362690Z","iopub.status.busy":"2024-05-20T05:39:39.362374Z"},"trusted":true,"id":"hgNArXcdhunM","outputId":"e2d513cb-64a0-461d-aca8-aa1f283fbb1e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Premature end of JPEG file\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 1 || Train loss : 2.722 || Train accuracy : 0.336 Test loss : 2.047 || Test accuracy : 0.542\n"]},{"name":"stderr","output_type":"stream","text":["Premature end of JPEG file\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 2 || Train loss : 1.875 || Train accuracy : 0.574 Test loss : 1.602 || Test accuracy : 0.619\n"]},{"name":"stderr","output_type":"stream","text":["Premature end of JPEG file\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 3 || Train loss : 1.530 || Train accuracy : 0.636 Test loss : 1.397 || Test accuracy : 0.651\n"]},{"name":"stderr","output_type":"stream","text":["Premature end of JPEG file\n"]}],"source":["tune_model(10, model_efficientnet, trainloader, testloader, loss, optimizer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"aymW0F-ThunN"},"outputs":[],"source":["# Load the saved model weights\n","model_mobilenet.cpu()\n","torch.save(model_efficientnet, f\"/kaggle/working/model_efficientnet_cpu.pth\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":2852448,"sourceId":6116155,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}