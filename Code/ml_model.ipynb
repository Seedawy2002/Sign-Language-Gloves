{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gyro_x  gyro_y  gyro_z  flex1  flex2  flex3  flex4  flex5  contact1  \\\n",
      "0  -29.09    3.73    7.27   0.58   1.30   1.81   0.91   0.90       0.0   \n",
      "1  -29.09    3.73    7.27   0.58   1.30   1.81   0.91   0.90       0.0   \n",
      "2  -29.09    3.74    7.26   0.60   1.31   1.80   0.91   0.91       0.0   \n",
      "3  -29.09    3.74    7.26   0.60   1.31   1.80   0.91   0.91       0.0   \n",
      "4  -29.09    3.74    7.24   0.57   1.31   1.81   0.91   0.91       0.0   \n",
      "\n",
      "   contact2  contact3 char  \n",
      "0       0.0       1.0    ا  \n",
      "1       0.0       1.0    ا  \n",
      "2       0.0       1.0    ا  \n",
      "3       0.0       1.0    ا  \n",
      "4       0.0       1.0    ا  \n"
     ]
    }
   ],
   "source": [
    "# Path to the original dataset\n",
    "file_path ='C:/Users/Gehan/sensor_data.csv'\n",
    "\n",
    "# Temporary file path for the cleaned data\n",
    "cleaned_file_path = 'C:/Users/Gehan/cleaned_sensor_data.csv'\n",
    "\n",
    "# Process the file to remove rows with incorrect number of commas\n",
    "expected_commas = 11  # As there are 12 columns, we expect 11 commas\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as file, open(cleaned_file_path, 'w', encoding=\"utf-8\") as outfile:\n",
    "    for line in file:\n",
    "        if line.count(',') == expected_commas:\n",
    "            outfile.write(line)\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data = pd.read_csv(cleaned_file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             gyro_x        gyro_y        gyro_z         flex1         flex2  \\\n",
      "count  97106.000000  97108.000000  97108.000000  97108.000000  97108.000000   \n",
      "mean      -5.828310    -18.084606   -153.363960      0.840781      1.700128   \n",
      "std       44.695019     72.074772    548.872241      2.666640      4.667013   \n",
      "min    -2981.000000  -2733.000000 -26293.000000      0.000000      0.160000   \n",
      "25%       -5.240000    -20.940000   -206.440000      0.540000      1.270000   \n",
      "50%       -1.830000    -20.060000   -129.090000      0.620000      1.400000   \n",
      "75%       -0.240000    -17.790000   -101.940000      0.970000      1.680000   \n",
      "max     1139.000000   1501.000000    247.420000    139.000000    244.000000   \n",
      "\n",
      "              flex3         flex4         flex5  contact1      contact2  \\\n",
      "count  97108.000000  97108.000000  97108.000000   96974.0  96966.000000   \n",
      "mean       2.315228      1.439219      1.010773       0.0      0.000371   \n",
      "std        6.879318      4.927896      3.330346       0.0      0.019265   \n",
      "min        0.040000      0.000000      0.000000       0.0      0.000000   \n",
      "25%        1.720000      1.040000      0.830000       0.0      0.000000   \n",
      "50%        1.970000      1.280000      0.900000       0.0      0.000000   \n",
      "75%        2.490000      1.470000      0.990000       0.0      0.000000   \n",
      "max      260.000000    163.000000    124.000000       0.0      1.000000   \n",
      "\n",
      "           contact3  \n",
      "count  96992.000000  \n",
      "mean       0.265599  \n",
      "std        0.441654  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyro_x        2\n",
      "gyro_y        0\n",
      "gyro_z        0\n",
      "flex1         0\n",
      "flex2         0\n",
      "flex3         0\n",
      "flex4         0\n",
      "flex5         0\n",
      "contact1    134\n",
      "contact2    142\n",
      "contact3    116\n",
      "char          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Handling missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:  0.6787985317685985\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical variable 'char' if it's not numeric\n",
    "if data['char'].dtype == 'object':\n",
    "    char_to_int = {char: idx for idx, char in enumerate(data['char'].unique())}\n",
    "    int_to_char = {idx: char for char, idx in char_to_int.items()}\n",
    "    data['char'] = data['char'].map(char_to_int)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X = data.drop('char', axis=1)\n",
    "y = data['char']\n",
    "columns_to_scale = [col for col in X.columns if not col.startswith('contact')]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the features that need scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test_scaled[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "\n",
    "# Model training\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test the model\n",
    "predictions = model.predict(X_test_scaled)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy of the model: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5168794912888384\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model with threshold: 0.9630874218063382\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = random_forest_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of the model with threshold: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model with threshold: 0.941219045649589\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "probabilities = random_forest_model.predict_proba(X_test)\n",
    "\n",
    "# Define a threshold\n",
    "threshold = 0.7  # You can adjust this based on your requirements\n",
    "\n",
    "# Apply the threashold to determine labels\n",
    "# We need to find the maximum probability from the probabilities array and check if it is below the threshold\n",
    "max_probabilities = np.max(probabilities, axis=1)\n",
    "predictions = np.where(max_probabilities < threshold, -1, random_forest_model.predict(X_test))  # Assuming -1 represents 'nothing'\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of the model with threshold: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
