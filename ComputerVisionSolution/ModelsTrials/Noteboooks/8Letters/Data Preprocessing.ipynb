{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## About"],"metadata":{"id":"QbF_yvAl-9rL"}},{"cell_type":"markdown","source":["**Notebook overview**\n","\n","This notebook involves the preprocessing a subset of the ArSL dataset. We follow the common preprocessing techniques found in the literature for classification of sign languages."],"metadata":{"id":"oY88qkRkx7la"}},{"cell_type":"markdown","source":["The following are the preprocessing techniques applied to the chosen subset of the dataset.\n","\n","1. **Image resizing**: The images are resized to (3, 224, 224) where 3 represents the number of channels (RGB) in the image and (224, 224) represents the 2D dimensions of each image.\n","\n","2. **Normalization**: Scaling pixel values to a range, typically between 0 and 1, helps in speeding up convergence during training.\n","\n","3. **Data Augmentation**: To make the model robust to various orientations and scales, augmenting the dataset with transformed images (e.g., rotations, scaling, translations, flipping) is beneficial."],"metadata":{"id":"J5Bfg-ibyvdF"}},{"cell_type":"markdown","source":["## Needed libraries"],"metadata":{"id":"hJeAYwZdCW_E"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import os\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms.v2 as transforms\n","import torchvision.models\n","from  torch.utils.data import DataLoader, Dataset\n","from albumentations.pytorch import ToTensorV2\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"id":"D30ringWCWp4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716205875768,"user_tz":-180,"elapsed":4,"user":{"displayName":"Omar Ayman 202100443","userId":"15890558693493219656"}},"outputId":"4f8ffe50-9fd6-4bec-81a1-4e62b5e90485"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["## Loading data from Google drive"],"metadata":{"id":"YmKxPu6sBFKT"}},{"cell_type":"markdown","source":["### Mount the drive"],"metadata":{"id":"b8MpxvUxBNEZ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"6wmijUeGBMrv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716205879673,"user_tz":-180,"elapsed":1807,"user":{"displayName":"Omar Ayman 202100443","userId":"15890558693493219656"}},"outputId":"b446613e-a01d-4d80-ebc6-b4b228eaa4b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### Loading images from the drive"],"metadata":{"id":"xX4nXiXxCgi1"}},{"cell_type":"code","source":["# Load data from numpy arrays\n","destination_folder = \"/content/drive/Shared drives/Computer Vision/Data/Resized_RGB_ArSL_dataset_numpy\"\n","\n","# Get list of .npy files in the directory\n","files = [file for file in os.listdir(destination_folder)]\n","\n","# Initialize lists to store image arrays and labels\n","image_arrays = []\n","labels = []\n","\n","# Read each .npy file and append its numpy array and label to the lists\n","for file in files:\n","    # Extract label from file name\n","    label = file.split('_')[0]\n","    # Load numpy array\n","    array = np.load(os.path.join(destination_folder, file))\n","    # Append to lists\n","    image_arrays.append(array)\n","    labels.append(label)\n","\n","# Convert lists to numpy arrays\n","image_arrays = np.array(image_arrays)\n","labels = np.array(labels)"],"metadata":{"id":"MItBogJ0Cjiw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Image resizing"],"metadata":{"id":"-hN5RFSshJ43"}},{"cell_type":"markdown","source":["### Converting numpy arrays to images and resizing then"],"metadata":{"id":"RvwemvmRdxie"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLn2CP-c5aOv"},"outputs":[],"source":["images = []\n","# Convert each NumPy array to an image using PIL\n","for array in image_arrays:\n","    # Convert the array to an image and resize it\n","    image = Image.fromarray(array).resize((224, 224))\n","    images.append(image)"]},{"cell_type":"markdown","source":["## Data splitting, Normalization, and Data Augmentation  "],"metadata":{"id":"e0-XOCv7vEKj"}},{"cell_type":"markdown","source":["### Data splitting and one hot encoding"],"metadata":{"id":"gj1bYlLvgUOA"}},{"cell_type":"code","source":["train_data, test_data, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, stratify=labels)"],"metadata":{"id":"ynAm_QT6TK-e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transform images to tensors\n","\n","transform = transforms.ToTensor()\n","train_data = [transform(img) for img in train_data]\n","test_data = [transform(img) for img in test_data]"],"metadata":{"id":"ylx27XDb5L9F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716205951841,"user_tz":-180,"elapsed":2841,"user":{"displayName":"Omar Ayman 202100443","userId":"15890558693493219656"}},"outputId":"77849072-7715-4042-94c7-0b5ab70871c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# One hot encoding\n","\n","label_encoder = LabelEncoder()\n","train_labels = label_encoder.fit_transform(train_labels)\n","test_labels = label_encoder.fit_transform(test_labels)"],"metadata":{"id":"gaT5y4Iu33WR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Augmentation and Normalization"],"metadata":{"id":"zkIUBqZIgLjP"}},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, x, y, transforms=None):\n","        self.x = x\n","        self.y = y\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","    def __getitem__(self, idx):\n","        x = self.x[idx]\n","        y = self.y[idx]\n","\n","        if self.transforms:\n","            x = self.transforms(x)\n","\n","        return x, y"],"metadata":{"id":"TPiBe5HHTviG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Can add multiple transformations to enhance the training of the model\n","\n","train_transforms = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomRotation(30),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","test_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"8Sk0_kxrat5T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716205957447,"user_tz":-180,"elapsed":3,"user":{"displayName":"Omar Ayman 202100443","userId":"15890558693493219656"}},"outputId":"67809c08-c593-4ef5-e43e-4c2803a43fa9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["trainset = MyDataset(train_data, train_labels, train_transforms)\n","trainloader_ = DataLoader(trainset, batch_size=5, shuffle=True)\n","\n","testset = MyDataset(test_data, test_labels, test_transforms)\n","testloader_ = DataLoader(testset, batch_size=5, shuffle=False)"],"metadata":{"id":"4XqGe9zVUK4h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Models Fine Tuning"],"metadata":{"id":"px5kdCEHclk4"}},{"cell_type":"markdown","source":["### Functions"],"metadata":{"id":"mU8mYMP0dHa0"}},{"cell_type":"code","source":["def train(model, dataloader, loss, optimizer, device, scheduler=None):\n","    model.train()\n","    acc = []\n","    lss_history = []\n","    for _ , (data, labels) in enumerate(dataloader):\n","        data = data.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        pred = model(data)\n","        lss = loss(pred, labels)\n","\n","        lss.backward()\n","        optimizer.step()\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        # acc calculations\n","        lss_history.append(lss.item())\n","        acc.append(((pred.argmax(axis = 1) == labels).type(torch.float)).mean().item())\n","    return np.mean(lss_history) ,np.mean(acc)\n","\n","# function to validate the model\n","def validate(model, dataloader, device, loss_func):\n","    model.eval()\n","    loss_values = []\n","    acc_values = []\n","    with torch.no_grad():\n","      for _, (data, labels) in enumerate(dataloader):\n","        data = data.to(device)\n","        labels = labels.to(device)\n","        pred = model(data)\n","        loss = loss_func(pred, labels)\n","        loss_values.append(loss.item())\n","        acc_value = (pred.argmax(axis = 1) == labels).type(torch.float32)\n","        acc_values.append(acc_value.mean().item())\n","    return np.mean(loss_values), np.mean(acc_values)"],"metadata":{"id":"iI-s0bvE0zg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tune_model(epochs, model, train_dataloader, test_dataloader, loss_func, optimizer, device, scheduler=None):\n","    for epoch in range(epochs):\n","      train_loss, train_acc = train(model, train_dataloader, loss_func, optimizer, device, scheduler)\n","      test_loss, test_acc = validate(model, test_dataloader, device, loss_func)\n","      print(f\"Epoch : {epoch + 1} || Train loss : {train_loss:5.3f} || Train accuracy : {train_acc:5.3f}\", end=\"\")\n","      print(f\" || Test loss : {test_loss:5.3f} || Test accuracy : {test_acc:5.3f}\")"],"metadata":{"id":"OfIt-oMo1Vg5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Models"],"metadata":{"id":"2SVOuQeDdNGn"}},{"cell_type":"markdown","source":["#### Resnet18"],"metadata":{"id":"A54Haj5_ct-d"}},{"cell_type":"code","source":["model_resnet18 = torch.load(\"/content/drive/Shared drives/Computer Vision/Models (Before fine-tuning)/resnet18.pth\" )\n","for name, param in model_resnet18.named_parameters():\n","    if \"layer4\" in name or \"fc\" in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False\n","\n","model_resnet18.fc = nn.Linear(512, 8)\n","model_resnet18 = model_resnet18.to(device)\n","print(model_resnet18)"],"metadata":{"id":"w08lQtnB005u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716205968386,"user_tz":-180,"elapsed":1980,"user":{"displayName":"Omar Ayman 202100443","userId":"15890558693493219656"}},"outputId":"4a6aa9ba-8f05-49f6-b93c-63a384aac4d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=8, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model_resnet18.parameters(), lr=0.0001)"],"metadata":{"id":"y5yxKRcp3fFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tune_model(10, model_resnet18, trainloader_, testloader_, loss, optimizer, device)\n","torch.save(model_resnet18, \"/content/drive/Shared drives/Computer Vision/Trained models/resnet18.pth\")"],"metadata":{"id":"O4geLUmg4GlK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716199216903,"user_tz":-180,"elapsed":222529,"user":{"displayName":"Mariam Elseedawy 201-901-281","userId":"07762662553666935170"}},"outputId":"a72a1c61-3079-41be-b3e5-faa7c11e6eb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 1 || Train loss : 0.859 || Train accuracy : 0.715 || Test loss : 0.232 || Test accuracy : 0.948\n","Epoch : 2 || Train loss : 0.375 || Train accuracy : 0.884 || Test loss : 0.178 || Test accuracy : 0.938\n","Epoch : 3 || Train loss : 0.285 || Train accuracy : 0.911 || Test loss : 0.123 || Test accuracy : 0.975\n","Epoch : 4 || Train loss : 0.215 || Train accuracy : 0.941 || Test loss : 0.087 || Test accuracy : 0.980\n","Epoch : 5 || Train loss : 0.192 || Train accuracy : 0.941 || Test loss : 0.089 || Test accuracy : 0.980\n","Epoch : 6 || Train loss : 0.151 || Train accuracy : 0.960 || Test loss : 0.110 || Test accuracy : 0.980\n","Epoch : 7 || Train loss : 0.136 || Train accuracy : 0.962 || Test loss : 0.074 || Test accuracy : 0.985\n","Epoch : 8 || Train loss : 0.112 || Train accuracy : 0.971 || Test loss : 0.079 || Test accuracy : 0.983\n","Epoch : 9 || Train loss : 0.079 || Train accuracy : 0.979 || Test loss : 0.089 || Test accuracy : 0.975\n","Epoch : 10 || Train loss : 0.104 || Train accuracy : 0.970 || Test loss : 0.088 || Test accuracy : 0.985\n"]}]},{"cell_type":"markdown","source":["#### Resnet50"],"metadata":{"id":"iLl8iFwbc0A0"}},{"cell_type":"code","source":["model_resnet50 = torch.load(\"/content/drive/Shared drives/Computer Vision/Models (Before fine-tuning)/resnet50.pth\")"],"metadata":{"id":"tgIu8qMPPrGW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name, param in model_resnet50.named_parameters():\n","    if \"fc\" in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False\n","\n","model_resnet50.fc = nn.Linear(2048, 8)\n","print(model_resnet50)"],"metadata":{"id":"ooUcxj6U96m6","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716199228191,"user_tz":-180,"elapsed":735,"user":{"displayName":"Mariam Elseedawy 201-901-281","userId":"07762662553666935170"}},"outputId":"dd665310-293d-465f-edf4-84c8fb3b8688"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=8, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["model_resnet50 = model_resnet50.to(device)"],"metadata":{"id":"YdTDN3EtQp0l","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model_resnet50.parameters(), lr=0.0001)\n","# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n","tune_model(10, model_resnet50, trainloader_, testloader_, loss, optimizer, device)\n","torch.save(model_resnet50, \"/content/drive/Shared drives/Computer Vision/Trained models/resnet50.pth\")"],"metadata":{"id":"z1C1Lgr2UAIL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716200208280,"user_tz":-180,"elapsed":235071,"user":{"displayName":"Mariam Elseedawy 201-901-281","userId":"07762662553666935170"}},"outputId":"2b9d6bb7-2668-4da4-e986-1d9b51359b7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 1 || Train loss : 0.405 || Train accuracy : 0.880 || Test loss : 0.446 || Test accuracy : 0.854\n","Epoch : 2 || Train loss : 0.407 || Train accuracy : 0.885 || Test loss : 0.397 || Test accuracy : 0.869\n","Epoch : 3 || Train loss : 0.419 || Train accuracy : 0.876 || Test loss : 0.484 || Test accuracy : 0.832\n","Epoch : 4 || Train loss : 0.412 || Train accuracy : 0.880 || Test loss : 0.440 || Test accuracy : 0.847\n","Epoch : 5 || Train loss : 0.407 || Train accuracy : 0.882 || Test loss : 0.420 || Test accuracy : 0.862\n","Epoch : 6 || Train loss : 0.398 || Train accuracy : 0.879 || Test loss : 0.438 || Test accuracy : 0.857\n","Epoch : 7 || Train loss : 0.402 || Train accuracy : 0.880 || Test loss : 0.423 || Test accuracy : 0.849\n","Epoch : 8 || Train loss : 0.424 || Train accuracy : 0.876 || Test loss : 0.455 || Test accuracy : 0.852\n","Epoch : 9 || Train loss : 0.410 || Train accuracy : 0.881 || Test loss : 0.444 || Test accuracy : 0.854\n","Epoch : 10 || Train loss : 0.396 || Train accuracy : 0.888 || Test loss : 0.441 || Test accuracy : 0.844\n"]}]},{"cell_type":"markdown","source":["#### MobileNetV2"],"metadata":{"id":"bHI9uEMDdWrz"}},{"cell_type":"code","source":["model_MobileNetV2 = torch.load(\"/content/drive/Shared drives/Computer Vision/Models (Before fine-tuning)/MobileNetV2.pth\")\n","for name, param in model_MobileNetV2.named_parameters():\n","    if \"classifier\" in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False\n","\n","model_MobileNetV2.classifier[1] = nn.Linear(1280, 8, bias=True)\n","print(model_MobileNetV2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"QCu0tFooV7XK","executionInfo":{"status":"ok","timestamp":1716205978869,"user_tz":-180,"elapsed":262,"user":{"displayName":"Omar Ayman 202100443","userId":"15890558693493219656"}},"outputId":"43ede304-062f-4036-d3e0-cc2f4a0949d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MobileNetV2(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): Conv2dNormActivation(\n","      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=1280, out_features=8, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["model_MobileNetV2 = model_MobileNetV2.to(device)"],"metadata":{"id":"n38gKkC4ghlh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model_MobileNetV2.parameters(), lr=0.001)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n","tune_model(10, model_MobileNetV2, trainloader_, testloader_, loss, optimizer, device, scheduler)\n","torch.save(model_MobileNetV2, \"/content/drive/Shared drives/Computer Vision/Trained models/MobileNetV2.pth\")"],"metadata":{"id":"w0oBZH1ui_MC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716207323274,"user_tz":-180,"elapsed":1315469,"user":{"displayName":"Omar Ayman 202100443","userId":"15890558693493219656"}},"outputId":"ff9f87c7-4a65-4482-b2f2-93b83c9c4792"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 1 || Train loss : 1.853 || Train accuracy : 0.337 || Test loss : 1.588 || Test accuracy : 0.417\n","Epoch : 2 || Train loss : 1.545 || Train accuracy : 0.510 || Test loss : 1.341 || Test accuracy : 0.607\n","Epoch : 3 || Train loss : 1.337 || Train accuracy : 0.611 || Test loss : 1.141 || Test accuracy : 0.689\n","Epoch : 4 || Train loss : 1.215 || Train accuracy : 0.636 || Test loss : 1.045 || Test accuracy : 0.691\n","Epoch : 5 || Train loss : 1.116 || Train accuracy : 0.673 || Test loss : 0.964 || Test accuracy : 0.711\n","Epoch : 6 || Train loss : 1.080 || Train accuracy : 0.661 || Test loss : 0.860 || Test accuracy : 0.746\n","Epoch : 7 || Train loss : 1.014 || Train accuracy : 0.668 || Test loss : 0.860 || Test accuracy : 0.753\n","Epoch : 8 || Train loss : 0.987 || Train accuracy : 0.689 || Test loss : 0.801 || Test accuracy : 0.728\n","Epoch : 9 || Train loss : 0.942 || Train accuracy : 0.685 || Test loss : 0.751 || Test accuracy : 0.778\n","Epoch : 10 || Train loss : 0.934 || Train accuracy : 0.692 || Test loss : 0.756 || Test accuracy : 0.763\n"]}]}]}